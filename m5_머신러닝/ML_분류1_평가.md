## 정확도 / 정밀도 / 재현율 / F1 Score / ROC AUC
  - 모델의 성능을 다양한 관점에서 평가하는 데 중요한 지표

  TN FP
  FN TP

  TN : 음수(Negative)로 예측, True로 판명 (=음수)
  FP : 양수(Positive)로 예측, False로 판명 (=음수)
  FN : 음수(Negative)로 예측, False로 판명 (=양수)
  TP : 양수(Positive)로 예측, True로 판명 (=양수)


  #### 정확도 (Accuracy)
    - 모델이 전체 데이터 중 얼마나 정확히 예측했는가 (TP의 비중)
    - (TP + TN) / (TN + FP + FN + TP)

  #### 정밀도 (Precision)
    - 모델이 양성이라 예측한 데이터들 중 실제 양성인 경우의 비율
    - TP / (TP + FP)

  #### 재현율 (Recall) / 감도 (Sensitivity)
    - 실제 양성인 데이터 중 모델이 양성으로 올바르게 예측한 비율
    - TP / (TP + FN)

  #### F1 Score
    - 정밀도와 재현율의 균형을 나타내는 지표로, 모델이 얼마나 잘 예측하는지에 대한 측정치. 불균형 데이터셋에서 유용하다.
    - 2 * (precision * recall) / (precision + recall)

  #### ROC AUC (Receiver Operating Charactieristic - Area Under Curve)
    - ROC 곡선 : 모델의 예측 성능을 그래프로 나타낸 것
    - 재현율 vs 1-특이성(음성 값을 양성으로 잘못 예측한 비율)의 관계 그래프

    - AUC 값 : ROC 곡선 아래의 면적
    - 값이 1에 가까울 수록 더 좋은 모델로 평가 (0 ~ 1사이)

## ROC 곡선과 AUC
  - 재현율(민감도)과 특이성 간의 관계를 나타내는 곡선
  - 특이성(TNR) : (TN + FP)/(TN + FP) - TN/(TN + FP) = FP / (TN+FP)
  - fprs, tprs, thresholds = 곡선도 그리기 위한 데이터 ( roc_curve 사용 )
  - label_binarize를 사용하여 이진 클래스 이상, 다중 클래스 라벨을 이진화하여 분류할 수도 있다.

## 정밀도와 재현률 : 트레이드오프 관계성
  - 둘 중 한쪽이 높아지면 다른 하나의 수치는 낮아지는 트레이드오프 관계이다.
  - 때에 따라서 정밀도가 높아야하는 경우, 재현률이 높아야하는 경우가 있다.
    - 정밀도가 높아야 하는 경우 : 스팸 메일. 중요 메일을 스팸메일로 분류하면 발생하는 문제가 크기 때문에 정밀하게 분류해야한다.
    - 재현률이 높아야 하는 경우 : 암 진단. 암일 수도 아닐 수도 있으나 기준을 높게 잡아 암을 진단하는 경우 초기 암을 놓칠 가능성이 있다. 그러므로 임곗값(Threshold)을 낮춰 더 많은 양수를 예측해야한다.

    #### sklearn : predict_proba()
      - 개별 레이블 별 결정 확률을 반환하는 함수
      - 이진 분류 모델에서 예측 확률이 큰 레이블 값으로 예측하는데, 특정 데이터가 0이 될 확률이 10%, 1이 될 확률이 90%로 예측되었다면 최종 예측은 더 큰 확률을 가진 1로 예측되는 것
      - 이진 분류에서는 임곗값을 대체적으로 0.5로 두고 이 기준값 이상일 경우 Positive, 작으면 Negative로 결정한다.
      - predict() 메서드와 유사하지만 둘의 차이점은 predict는 둘 중 결정값을 반환, predict_proba()는 결정 전의 예측 확률 결과를 지원한다.
      - roc_auc를 구할 때 predict_proba(X_test)[:,1]로 예측의 양성 확률을 넣어 구한다.

## IQR 방법을 사용한 이상치 제거
  - IQR은 데이터의 중앙값, 데이터 변동성을 측정하는데 사용한다.
  - IQR = Q3 - Q1
  - 이상치 경계 계산
    - Lower Bound : Q1 - 1.5 * IQR
    - Upper Bound : Q3 + 1.5 * IQR

## 레이블 인코딩 / 원-핫 인코딩
  - 원-핫 인코딩 : 비순서 범주형 변수
    - 예를들어 성별(sex) 등의 변수는 순서가 없다. 이 경우, 각 범주를 고유한 이진 벡터로 변화하는 것이 적합
    - Logistic Regression과 같은 선형 모델과 같이 입력 변수를 독립적으로 가정하는 모델에 도움이 된다.
    - 다중공선성 방지 : drop_first=True 옵션으로 첫 번째 범주를 제거할 수 있다.
  
  - 레이블 인코딩 : 순서 범주형 변수
    - 초-중-고-대학교 등 범주에 순서가 있는 경우에 적합하다.
    - 결정 트리, 랜덤 포레스트, XGBoost와 같은 트리 기반 모델은 레이블 인코딩이 유리하다.

## 로지스틱 회귀 모델 solver 'lbfgs'
  - 최적화 알고리즘 L-BFGS를 사용하여 모델의 파라미터를 최적화.
  - 대규모 문제에서 효율적으로 동작하는 비선형 최적화 알고리즘

## SVC probability=True
  - 확률 값을 반환하게 하여 predict_proba 메서드를 사용할 수 있게 함

## 데이터 스케일링 (표준화)
  - StandardScaler
  - scaler.fit_transform()을 사용하여 X_train과 X_test를 스케일링(표준화)하여 데이터 간의 특성을 표준화 -> 특성 평균을 0, 표준편차 1로 변환

## 다중 클래스 분류 모델

  #### make_classification
    - n_samples : 데이터셋의 포함될 샘플의 수
    - n_features : 각 샘플이 가질 특성(레이블) 수
    - n_classes : 타겟 라벨의 클래스 수
    - n_informative : features 수 중 00개를 타겟 라벨과 관련된 유용한 정보로 지정, 나머지는 무작위 생성

  #### average 매개변수 옵션
    - macro : 각 클래스의 정밀도를 개별적으로 계산하여 단순 평균을 구한다. 클래스 간 불균형에 유용
    - micro : 전체 TP, FP, FN을 합쳐 정밀도를 계산.
    - samples : 다중 레이블 분류에 사용. 각 샘플에 개별적으로 메트릭을 계산 후 평균을 구한다.
    - None : 각 클래스별 정밀도 반환

  
