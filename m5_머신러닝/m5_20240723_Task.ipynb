{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task1_0723. 'Breast Cancer Wisconsin (Diagnostic) Data Set'을 사용하여 이진 분류 문제를 해결하고, 평가 지표(정확도, 정밀도, 재현율, F1 스코어, ROC AUC)를 계산하세요."
      ],
      "metadata": {
        "id": "8arVdMK5Qn4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmKcTz9dQlA3"
      },
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "threshold = 0.5\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 표준화\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 로지스틱 회귀 모델 학습\n",
        "lr_clf = LogisticRegression(max_iter=500, solver='lbfgs', random_state=42)\n",
        "lr_clf.fit(X_train_scaled, y_train)\n",
        "pred = lr_clf.predict(X_test_scaled)\n",
        "\n",
        "# 성능평가\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "precision = precision_score(y_test, pred)\n",
        "recall = recall_score(y_test, pred)\n",
        "f1 = f1_score(y_test, pred)\n",
        "roc_auc = roc_auc_score(y_test, pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaq1pjREpmds",
        "outputId": "6233b022-7db6-4fc1-f770-bd32c843fc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Precision: 0.97\n",
            "Recall: 0.99\n",
            "F1-score: 0.98\n",
            "ROC AUC: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task2_0723.\n",
        "가상의 데이터셋을 생성하고, 이를 사용하여 다중 클래스 분류 모델을 훈련시킨 후 평가 지표를 계산하세요. 평가 지표는 정확도, 정밀도, 재현율, F1 스코어, ROC AUC입니다.\n",
        "\n",
        "- n_samples=1500: 데이터셋에 포함될 샘플의 수를 1500개로 지정합니다.\n",
        "- n_features=20: 각 샘플이 가질 특성(feature)의 수를 20개로 지정합니다.\n",
        "- n_classes=5: 타겟 라벨의 클래스 수를 5개로 지정합니다.\n",
        "- n_informative=15: 20개의 특성 중 15개는 타겟 라벨과 관련된 유용한 정보를 포함하도록 지정합니다. 나머지 5개의 특성은 유용하지 않거나 무작위로 생성된 특성입니다.\n",
        "- random_state=42: 재현성을 위해 난수 생성 seed를 설정합니다."
      ],
      "metadata": {
        "id": "JMdIFXAfQqFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# 데이터 생성 (5개의 클래스)\n",
        "X, y = make_classification(n_samples=1500, n_features=20, n_classes=5, n_informative=15, random_state=42)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 다중클래스 분류를 위한 랜덤 포레스트 모델 생성 및 학습\n",
        "forest_model = RandomForestClassifier()\n",
        "forest_model.fit(X_train, y_train)\n",
        "\n",
        "pred = forest_model.predict(X_test)\n",
        "\n",
        "# 다중 클래스 라벨 이진화\n",
        "y_test_binarized = label_binarize(y_test, classes=[0,1,2,3,4])\n",
        "pred_binarized = label_binarize(pred, classes=[0,1,2,3,4])\n",
        "\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "precision = precision_score(y_test_binarized, pred_binarized, average='macro')\n",
        "recall = recall_score(y_test_binarized, pred_binarized, average='macro')\n",
        "f1 = f1_score(y_test_binarized, pred_binarized, average='macro')\n",
        "roc_auc = roc_auc_score(y_test_binarized, pred_binarized, average='macro', multi_class='ovr')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.2f}\")"
      ],
      "metadata": {
        "id": "WwXrAGuPQrlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d091039c-138d-4050-835e-d7004b9e3d03"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79\n",
            "Precision: 0.80\n",
            "Recall: 0.80\n",
            "F1-score: 0.79\n",
            "ROC AUC: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1. 데이터 로드\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "           'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# na_values = ? 는 ?로 되어있는 값들을 None값으로 처리한다는 의미\n",
        "data = pd.read_csv(url, header=None, names=columns, na_values='?', skipinitialspace=True)\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "Q1 = data['fnlwgt'].quantile(0.25)\n",
        "Q3 = data['fnlwgt'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "capital_fnlwgt_outliers = data[(data['fnlwgt'] < lower_bound) | (data['fnlwgt'] > upper_bound)]\n",
        "data = data.drop(capital_fnlwgt_outliers.index)\n",
        "\n",
        "Q1 = data['capital-gain'].quantile(0.25)\n",
        "Q3 = data['capital-gain'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "capital_gain_outliers = data[(data['capital-gain'] < lower_bound) | (data['capital-gain'] > upper_bound)]\n",
        "capital_loss_outliers = data[(data['capital-loss'] < lower_bound) | (data['capital-loss'] > upper_bound)]\n",
        "data = data.drop(capital_gain_outliers.index)\n",
        "data = data.drop(capital_loss_outliers.index)\n",
        "\n",
        "# 범주형 변수 인코딩\n",
        "\n",
        "categorical_features = ['race', 'sex', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'income']\n",
        "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# 변수 선택 및 데이터 분리\n",
        "\n",
        "X = data.drop('income_>50K', axis=1)\n",
        "y = data['income_>50K']\n",
        "\n",
        "# 파생변수1 : age_group\n",
        "data['age_group'] = pd.cut(data['age'], bins=[0, 18, 30, 45, 60, 100], labels=['0-18', '19-30', '31-45', '46-60', '61+'])\n",
        "\n",
        "# 파생변수2 : hours_group\n",
        "data['hours_group'] = pd.cut(data['hours-per-week'], bins=[0, 20, 40, 60, 100], labels=['0-20', '21-40', '41-60', '61+'])\n",
        "\n",
        "# 파생변수3 : capital\n",
        "data['capital'] = data['capital-gain'] - data['capital-loss']\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 표준화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 모델 초기화 및 학습\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = model.predict(X_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# 정확도 평가\n",
        "print(f\"Matrix: {conf_matrix}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Report: {class_report}\")\n",
        "print(f\"Accuracy: {accuracy_score}\")"
      ],
      "metadata": {
        "id": "-28t2bx6SB2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}