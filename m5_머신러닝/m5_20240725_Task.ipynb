{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task1_0725. 타이타닉 생존자 예측 데이터 세트 train.csv에 대하여 다음 사항을 수행하세요.\n",
        "- 일괄 전처리 사용자 함수 transform_features(df) 작성\n",
        "- 분류 모델 학습 및 평가 사용자 함수 작성\n",
        "- dt, lr, rf 모델링 및 평가(정확도)\n",
        "\n",
        "- GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행.\n",
        "  - Decision Tree, Random Forest, Logistic Regression 모델별 수행\n",
        "  - 선택한 모델에 적합한 parameter greed 적용\n",
        "  - cv=5 적용"
      ],
      "metadata": {
        "id": "IE2-xf_9TrDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def categorize_age(age):\n",
        "  if age < 13:\n",
        "      return 'Child'\n",
        "  elif age < 20:\n",
        "      return 'Teenager'\n",
        "  elif age < 60:\n",
        "      return 'Adult'\n",
        "  else:\n",
        "      return 'Senior'\n",
        "\n",
        "# 일괄 전처리 사용자 함수 transform_features(df)\n",
        "def transform_features(df):\n",
        "  # 이상치 처리\n",
        "  Q1 = df['Fare'].quantile(0.25)\n",
        "  Q3 = df['Fare'].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  fare_outliers = df[(df['Fare'] < (Q1 - 1.5 * IQR)) | (df['Fare'] > (Q3 + 1.5 * IQR))]\n",
        "\n",
        "  df = df.drop(fare_outliers.index)\n",
        "\n",
        "  # 결측치 처리\n",
        "  imputer_most_frequent = SimpleImputer(strategy='most_frequent')\n",
        "  df['Age'] = imputer_most_frequent.fit_transform(df[['Age']])\n",
        "  df['Fare'] = imputer_most_frequent.fit_transform(df[['Fare']])\n",
        "  df['Embarked'] = df['Embarked'].fillna('S')\n",
        "\n",
        "  # 파생변수 생성\n",
        "  df['Family_size'] = df['SibSp'] + df['Parch']\n",
        "\n",
        "  df['AgeGroup'] = df['Age'].apply(lambda x: categorize_age(x))\n",
        "\n",
        "  df['Pclass_Fare'] = df['Pclass'] * df['Fare']\n",
        "\n",
        "  df['TicketCount'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
        "\n",
        "  df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "  rare_titles = ['Don', 'Rev', 'Dr', 'Ms', 'Major', 'Lady', 'Sir', 'Col', 'Mlle', 'Jonkheer']\n",
        "  df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
        "\n",
        "  # 원본, 파생변수 모두 사용하는 경우\n",
        "  df = pd.get_dummies(df, columns=['Embarked', 'Sex', 'SibSp', 'Parch', 'Family_size', 'AgeGroup', 'TicketCount', 'Ticket'])\n",
        "  df.drop(columns=['PassengerId', 'Name', 'Cabin'], inplace=True)\n",
        "\n",
        "  # 파생변수만 사용하는 경우\n",
        "  # df = pd.get_dummies(df, columns=['Embarked', 'Family_size', 'AgeGroup', 'TicketCount', 'Sex'])\n",
        "  # df.drop(columns=['PassengerId', 'Name', 'Cabin', 'SibSp', 'Parch', 'Age', 'Pclass', 'Ticket', 'Fare' ], inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/KDT_2404/dataset/train.csv')\n",
        "\n",
        "df = transform_features(df)\n",
        "\n",
        "# 변수 선택 및 데이터 분리\n",
        "X = df.drop(columns=['Survived'])\n",
        "y = df['Survived']\n",
        "df.drop(columns=['Survived'], inplace=True)\n",
        "\n",
        "# 8. 학습용과 테스트용 데이터셋으로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# 7. 데이터 표준화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 모델 및 하이퍼파라미터 설정\n",
        "models = {\n",
        "    'Logistic Regression': (LogisticRegression(max_iter=1000), {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
        "    }),\n",
        "    'Decision Tree': (DecisionTreeClassifier(), {\n",
        "        'max_depth': [None, 10, 20, 30, 40],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }),\n",
        "    'Random Forest': (RandomForestClassifier(), {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    })\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# 하이퍼파라미터 튜닝 및 모델 학습\n",
        "for model_name, (model, params) in models.items():\n",
        "    grid_search = GridSearchCV(model, params, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
        "    results[model_name] = {\n",
        "        'Best Parameters': grid_search.best_params_,\n",
        "        'Accuracy': accuracy,\n",
        "        'ROC AUC': roc_auc\n",
        "    }\n",
        "\n",
        "# 결과 출력\n",
        "for model_name, result in results.items():\n",
        "    print(f'{model_name} - Best Parameters: {result[\"Best Parameters\"]}, Accuracy: {result[\"Accuracy\"]}, ROC AUC: {result[\"ROC AUC\"]}')\n",
        "\n",
        "# 원본+파생 결과 (random_state=60)\n",
        "# Logistic Regression - Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8774193548387097, ROC AUC: 0.8546666666666667\n",
        "# Decision Tree - Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.864516129032258, ROC AUC: 0.7828571428571429\n",
        "# Random Forest - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}, Accuracy: 0.8580645161290322, ROC AUC: 0.8727619047619047\n",
        "# Title 파생변수 없을 때 결과 (random_state=12\n",
        "# Logistic Regression - Best Parameters: {'C': 10, 'solver': 'newton-cg'}, Accuracy: 0.8580645161290322, ROC AUC: 0.8845801246791346\n",
        "# Decision Tree - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8516129032258064, ROC AUC: 0.8221488815548222\n",
        "# Random Forest - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, Accuracy: 0.8451612903225807, ROC AUC: 0.888980564723139Z)\n",
        "\n",
        "# Title파생변수 추가 결과 (random_state=60)\n",
        "# Logistic Regression - Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8774193548387097, ROC AUC: 0.8607619047619047\n",
        "# Decision Tree - Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.8516129032258064, ROC AUC: 0.7456190476190476\n",
        "# Random Forest - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.8709677419354839, ROC AUC: 0.8708571428571429\n",
        "# random_state=12\n",
        "# Logistic Regression - Best Parameters: {'C': 1, 'solver': 'liblinear'}, Accuracy: 0.8580645161290322, ROC AUC: 0.8933810047671433\n",
        "# Decision Tree - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.864516129032258, ROC AUC: 0.8344334433443344\n",
        "# Random Forest - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8580645161290322, ROC AUC: 0.8716538320498717\n",
        "\n",
        "\n",
        "# 파생만 사용했을 때 결과 (random_state=60)\n",
        "# Logistic Regression - Best Parameters: {'C': 0.1, 'solver': 'liblinear'}, Accuracy: 0.864516129032258, ROC AUC: 0.8327619047619047\n",
        "# Decision Tree - Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8516129032258064, ROC AUC: 0.8338095238095238\n",
        "# Random Forest - Best Parameters: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, Accuracy: 0.864516129032258, ROC AUC: 0.8586666666666667\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "\n",
        "# 가장 베스트 값으로 하이퍼파라메터 튜닝\n",
        "# models = {\n",
        "#   'Logistic Regression': LogisticRegression(C= 0.1, solver= 'saga'),\n",
        "#   'Decision Tree': DecisionTreeClassifier(max_depth= 10, min_samples_leaf= 4, min_samples_split= 5),\n",
        "#   'Random Forest': RandomForestClassifier(max_depth= 10, min_samples_leaf= 4, min_samples_split= 5)\n",
        "# }\n",
        "\n",
        "# # 10. 모델 학습 및 평가\n",
        "# for name, model in models.items():\n",
        "#   model.fit(X_train, y_train)\n",
        "#   y_pred = model.predict(X_test)\n",
        "#   accuracy = accuracy_score(y_test, y_pred)\n",
        "#   conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "#   class_report = classification_report(y_test, y_pred)\n",
        "#   roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "#   print(f'Model: {name}')\n",
        "#   print(f'Accuracy: {accuracy:.4f}')\n",
        "#   print('Confusion Matrix:')\n",
        "#   print(conf_matrix)\n",
        "#   print('Classification Report:')\n",
        "#   print(class_report)\n",
        "#   print(f'ROC AUC: {roc_auc:.4f}')\n",
        "#   print('\\n' + '='*60 + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzijk_Mk-ybG",
        "outputId": "64cb5bd8-7925-4b9d-fbe8-2fa00aa11131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Best Parameters: {'C': 10, 'solver': 'newton-cg'}, Accuracy: 0.8580645161290322, ROC AUC: 0.8845801246791346\n",
            "Decision Tree - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8516129032258064, ROC AUC: 0.8221488815548222\n",
            "Random Forest - Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, Accuracy: 0.8451612903225807, ROC AUC: 0.888980564723139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def categorize_age(age):\n",
        "  if age < 13:\n",
        "      return 'Child'\n",
        "  elif age < 20:\n",
        "      return 'Teenager'\n",
        "  elif age < 60:\n",
        "      return 'Adult'\n",
        "  else:\n",
        "      return 'Senior'\n",
        "\n",
        "# 일괄 전처리 사용자 함수 transform_features(df)\n",
        "def transform_features(df):\n",
        "  # 이상치 처리\n",
        "  Q1 = df['Fare'].quantile(0.25)\n",
        "  Q3 = df['Fare'].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  fare_outliers = df[(df['Fare'] < (Q1 - 1.5 * IQR)) | (df['Fare'] > (Q3 + 1.5 * IQR))]\n",
        "\n",
        "  df = df.drop(fare_outliers.index)\n",
        "\n",
        "  # 결측치 처리\n",
        "  imputer_most_frequent = SimpleImputer(strategy='most_frequent')\n",
        "  df['Age'] = imputer_most_frequent.fit_transform(df[['Age']])\n",
        "  df['Fare'] = imputer_most_frequent.fit_transform(df[['Fare']])\n",
        "  df['Embarked'] = df['Embarked'].fillna('S')\n",
        "\n",
        "  # 파생변수 생성\n",
        "  df['Family_size'] = df['SibSp'] + df['Parch']\n",
        "\n",
        "  df['AgeGroup'] = df['Age'].apply(lambda x: categorize_age(x))\n",
        "\n",
        "  df['Pclass_Fare'] = df['Pclass'] * df['Fare']\n",
        "\n",
        "  df['TicketCount'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
        "\n",
        "  df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "  rare_titles = ['Don', 'Rev', 'Dr', 'Ms', 'Major', 'Lady', 'Sir', 'Col', 'Mlle', 'Jonkheer']\n",
        "  df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
        "\n",
        "  # 원본, 파생변수 모두 사용하는 경우\n",
        "  df = pd.get_dummies(df, columns=['Embarked', 'Sex', 'SibSp', 'Parch', 'Family_size', 'AgeGroup', 'TicketCount', 'Ticket', 'Title'])\n",
        "  df.drop(columns=['PassengerId', 'Name', 'Cabin'], inplace=True)\n",
        "\n",
        "  # 파생변수만 사용하는 경우\n",
        "  # df = pd.get_dummies(df, columns=['Embarked', 'Family_size', 'AgeGroup', 'TicketCount', 'Sex'])\n",
        "  # df.drop(columns=['PassengerId', 'Name', 'Cabin', 'SibSp', 'Parch', 'Age', 'Pclass', 'Ticket', 'Fare' ], inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/KDT_2404/dataset/train.csv')\n",
        "\n",
        "df = transform_features(df)\n",
        "\n",
        "# 변수 선택 및 데이터 분리\n",
        "X = df.drop(columns=['Survived'])\n",
        "y = df['Survived']\n",
        "df.drop(columns=['Survived'], inplace=True)\n",
        "\n",
        "# 8. 학습용과 테스트용 데이터셋으로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
        "\n",
        "# 7. 데이터 표준화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "lr_clf = LogisticRegression(C= 0.1, solver= 'newton-cg')\n",
        "lr_clf.fit(X_train, y_train)\n",
        "y_pred = lr_clf.predict(X_test)\n",
        "y_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print(f'ROC AUC: {roc_auc_score(y_test, y_proba):.4f}')\n",
        "\n",
        "# Model: Decision Tree, Random State: 30, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.896774193548387, ROC AUC: 0.8560163551401869\n",
        "# Model: Logistic Regression, Random State: 37, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8838709677419355, ROC AUC: 0.8819758672699849\n",
        "# Model: Logistic Regression, Random State: 78, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8903225806451613, ROC AUC: 0.9101008215085885"
      ],
      "metadata": {
        "id": "QEZWE136Xg05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model: Logistic Regression, Random State: 31, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.832258064516129, ROC AUC: 0.8842383107088989\n",
        "Model: Decision Tree, Random State: 31, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8258064516129032, ROC AUC: 0.8329562594268477\n",
        "Model: Random Forest, Random State: 31, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8, ROC AUC: 0.8522812971342383\n",
        "Model: Logistic Regression, Random State: 32, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8129032258064516, ROC AUC: 0.8295625942684767\n",
        "Model: Decision Tree, Random State: 32, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.7870967741935484, ROC AUC: 0.7658371040723981\n",
        "Model: Random Forest, Random State: 32, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8387096774193549, ROC AUC: 0.7540535444947211\n",
        "Model: Logistic Regression, Random State: 33, Best Parameters: {'C': 1, 'solver': 'liblinear'}, Accuracy: 0.8387096774193549, ROC AUC: 0.8854285714285713\n",
        "Model: Decision Tree, Random State: 33, Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.8387096774193549, ROC AUC: 0.7971428571428572\n",
        "Model: Random Forest, Random State: 33, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.8193548387096774, ROC AUC: 0.8532380952380952\n",
        "Model: Logistic Regression, Random State: 34, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.864516129032258, ROC AUC: 0.8804153240243465\n",
        "Model: Decision Tree, Random State: 34, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8516129032258064, ROC AUC: 0.8490870032223417\n",
        "Model: Random Forest, Random State: 34, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8451612903225807, ROC AUC: 0.8709273182957394\n",
        "Model: Logistic Regression, Random State: 35, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8258064516129032, ROC AUC: 0.870716211012707\n",
        "Model: Decision Tree, Random State: 35, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.8387096774193549, ROC AUC: 0.7841740469772814\n",
        "Model: Random Forest, Random State: 35, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, Accuracy: 0.8129032258064516, ROC AUC: 0.8824605313823644\n",
        "Model: Logistic Regression, Random State: 36, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8258064516129032, ROC AUC: 0.8470847084708472\n",
        "Model: Decision Tree, Random State: 36, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8193548387096774, ROC AUC: 0.7871287128712872\n",
        "Model: Random Forest, Random State: 36, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8064516129032258, ROC AUC: 0.8217821782178217\n",
        "Model: Logistic Regression, Random State: 37, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8838709677419355, ROC AUC: 0.8819758672699849\n",
        "Model: Decision Tree, Random State: 37, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8451612903225807, ROC AUC: 0.827205882352941\n",
        "Model: Random Forest, Random State: 37, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8709677419354839, ROC AUC: 0.8346530920060332\n",
        "Model: Logistic Regression, Random State: 38, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8064516129032258, ROC AUC: 0.851008215085885\n",
        "Model: Decision Tree, Random State: 38, Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.8064516129032258, ROC AUC: 0.7686706497386109\n",
        "Model: Random Forest, Random State: 38, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, Accuracy: 0.7806451612903226, ROC AUC: 0.8258028379387602\n",
        "Model: Logistic Regression, Random State: 39, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8129032258064516, ROC AUC: 0.8600110011001101\n",
        "Model: Decision Tree, Random State: 39, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8258064516129032, ROC AUC: 0.7969380271360469\n",
        "Model: Random Forest, Random State: 39, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.8258064516129032, ROC AUC: 0.8545104510451045\n",
        "Model: Logistic Regression, Random State: 40, Best Parameters: {'C': 10, 'solver': 'liblinear'}, Accuracy: 0.8129032258064516, ROC AUC: 0.8218599033816425\n",
        "Model: Decision Tree, Random State: 40, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.7806451612903226, ROC AUC: 0.7348171152518979\n",
        "Model: Random Forest, Random State: 40, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8064516129032258, ROC AUC: 0.8218599033816424\n",
        "Model: Logistic Regression, Random State: 41, Best Parameters: {'C': 0.1, 'solver': 'liblinear'}, Accuracy: 0.8, ROC AUC: 0.8218085106382979\n",
        "Model: Decision Tree, Random State: 41, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.7870967741935484, ROC AUC: 0.692080378250591\n",
        "Model: Random Forest, Random State: 41, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.7935483870967742, ROC AUC: 0.8127462568951931\n",
        "Model: Logistic Regression, Random State: 42, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8129032258064516, ROC AUC: 0.858421052631579\n",
        "Model: Decision Tree, Random State: 42, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.7612903225806451, ROC AUC: 0.740877192982456\n",
        "Model: Random Forest, Random State: 42, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8129032258064516, ROC AUC: 0.832280701754386\n",
        "Model: Logistic Regression, Random State: 43, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.832258064516129, ROC AUC: 0.8400909090909092\n",
        "Model: Decision Tree, Random State: 43, Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8193548387096774, ROC AUC: 0.7972727272727274\n",
        "Model: Random Forest, Random State: 43, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.832258064516129, ROC AUC: 0.8464545454545453\n",
        "Model: Logistic Regression, Random State: 44, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8774193548387097, ROC AUC: 0.8682033096926713\n",
        "Model: Decision Tree, Random State: 44, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8258064516129032, ROC AUC: 0.7908786446020488\n",
        "Model: Random Forest, Random State: 44, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8580645161290322, ROC AUC: 0.8635736800630417\n",
        "Model: Logistic Regression, Random State: 45, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.864516129032258, ROC AUC: 0.9183256309989335\n",
        "Model: Decision Tree, Random State: 45, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.864516129032258, ROC AUC: 0.8591361535726982\n",
        "Model: Random Forest, Random State: 45, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8451612903225807, ROC AUC: 0.908016352648418\n",
        "Model: Logistic Regression, Random State: 46, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8258064516129032, ROC AUC: 0.8393333333333334\n",
        "Model: Decision Tree, Random State: 46, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.7935483870967742, ROC AUC: 0.7638095238095239\n",
        "Model: Random Forest, Random State: 46, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8193548387096774, ROC AUC: 0.8425714285714286\n",
        "Model: Logistic Regression, Random State: 47, Best Parameters: {'C': 10, 'solver': 'newton-cg'}, Accuracy: 0.864516129032258, ROC AUC: 0.8685567010309277\n",
        "Model: Decision Tree, Random State: 47, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.864516129032258, ROC AUC: 0.8428723782438678\n",
        "Model: Random Forest, Random State: 47, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.864516129032258, ROC AUC: 0.8744223249200141\n",
        "Model: Logistic Regression, Random State: 48, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8580645161290322, ROC AUC: 0.8996919522525991\n",
        "Model: Decision Tree, Random State: 48, Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8838709677419355, ROC AUC: 0.8687909125914517\n",
        "Model: Random Forest, Random State: 48, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, Accuracy: 0.8709677419354839, ROC AUC: 0.8920870234886408\n",
        "Model: Logistic Regression, Random State: 49, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8129032258064516, ROC AUC: 0.780909090909091\n",
        "Model: Decision Tree, Random State: 49, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.7935483870967742, ROC AUC: 0.7581818181818182\n",
        "Model: Random Forest, Random State: 49, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.8, ROC AUC: 0.7669090909090909\n",
        "Model: Logistic Regression, Random State: 50, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.832258064516129, ROC AUC: 0.867694805194805\n",
        "Model: Decision Tree, Random State: 50, Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.8387096774193549, ROC AUC: 0.8039321789321789\n",
        "Model: Random Forest, Random State: 50, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8516129032258064, ROC AUC: 0.8880772005772005\n",
        "Model: Logistic Regression, Random State: 51, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8, ROC AUC: 0.8723516949152542\n",
        "Model: Decision Tree, Random State: 51, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8516129032258064, ROC AUC: 0.8489583333333334\n",
        "Model: Random Forest, Random State: 51, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8258064516129032, ROC AUC: 0.8243290960451977\n",
        "Model: Logistic Regression, Random State: 52, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8064516129032258, ROC AUC: 0.8195488721804511\n",
        "Model: Decision Tree, Random State: 52, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8258064516129032, ROC AUC: 0.7821339061940565\n",
        "Model: Random Forest, Random State: 52, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.7935483870967742, ROC AUC: 0.7998567848191908\n",
        "Model: Logistic Regression, Random State: 53, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8193548387096774, ROC AUC: 0.8909736308316429\n",
        "Model: Decision Tree, Random State: 53, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8064516129032258, ROC AUC: 0.8029073698444896\n",
        "Model: Random Forest, Random State: 53, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}, Accuracy: 0.8451612903225807, ROC AUC: 0.862660581473969\n",
        "Model: Logistic Regression, Random State: 54, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.7677419354838709, ROC AUC: 0.8386842105263158\n",
        "Model: Decision Tree, Random State: 54, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.7741935483870968, ROC AUC: 0.7919298245614036\n",
        "Model: Random Forest, Random State: 54, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.8129032258064516, ROC AUC: 0.848859649122807\n",
        "Model: Logistic Regression, Random State: 55, Best Parameters: {'C': 10, 'solver': 'newton-cg'}, Accuracy: 0.832258064516129, ROC AUC: 0.8614529914529915\n",
        "Model: Decision Tree, Random State: 55, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.832258064516129, ROC AUC: 0.8247008547008546\n",
        "Model: Random Forest, Random State: 55, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, Accuracy: 0.832258064516129, ROC AUC: 0.8452136752136752\n",
        "Model: Logistic Regression, Random State: 56, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8516129032258064, ROC AUC: 0.9014972419227738\n",
        "Model: Decision Tree, Random State: 56, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8451612903225807, ROC AUC: 0.8204294720252165\n",
        "Model: Random Forest, Random State: 56, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}, Accuracy: 0.8451612903225807, ROC AUC: 0.8912529550827424\n",
        "Model: Logistic Regression, Random State: 57, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8580645161290322, ROC AUC: 0.9064002959674435\n",
        "Model: Decision Tree, Random State: 57, Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8774193548387097, ROC AUC: 0.8791157972623012\n",
        "Model: Random Forest, Random State: 57, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}, Accuracy: 0.864516129032258, ROC AUC: 0.8886422493525713\n",
        "Model: Logistic Regression, Random State: 58, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8451612903225807, ROC AUC: 0.857768691588785\n",
        "Model: Decision Tree, Random State: 58, Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.832258064516129, ROC AUC: 0.8115264797507789\n",
        "Model: Random Forest, Random State: 58, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}, Accuracy: 0.8451612903225807, ROC AUC: 0.8303154205607477\n",
        "Model: Logistic Regression, Random State: 59, Best Parameters: {'C': 10, 'solver': 'newton-cg'}, Accuracy: 0.832258064516129, ROC AUC: 0.8792255027813436\n",
        "Model: Decision Tree, Random State: 59, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8516129032258064, ROC AUC: 0.8215661103979461\n",
        "Model: Random Forest, Random State: 59, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8387096774193549, ROC AUC: 0.8770860077021824\n",
        "Model: Logistic Regression, Random State: 60, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8774193548387097, ROC AUC: 0.8607619047619047\n",
        "Model: Decision Tree, Random State: 60, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8451612903225807, ROC AUC: 0.7451428571428571\n",
        "Model: Random Forest, Random State: 60, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.8709677419354839, ROC AUC: 0.8805714285714286\n",
        "Model: Logistic Regression, Random State: 61, Best Parameters: {'C': 1, 'solver': 'liblinear'}, Accuracy: 0.8774193548387097, ROC AUC: 0.9247542997542998\n",
        "Model: Decision Tree, Random State: 61, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8580645161290322, ROC AUC: 0.8447993447993449\n",
        "Model: Random Forest, Random State: 61, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8838709677419355, ROC AUC: 0.8890253890253891\n",
        "Model: Logistic Regression, Random State: 62, Best Parameters: {'C': 10, 'solver': 'liblinear'}, Accuracy: 0.8709677419354839, ROC AUC: 0.8937077852826165\n",
        "Model: Decision Tree, Random State: 62, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8516129032258064, ROC AUC: 0.8401173124777818\n",
        "Model: Random Forest, Random State: 62, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}, Accuracy: 0.8709677419354839, ROC AUC: 0.8740668325630998\n",
        "Model: Logistic Regression, Random State: 63, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8193548387096774, ROC AUC: 0.8721904761904762\n",
        "Model: Decision Tree, Random State: 63, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}, Accuracy: 0.8064516129032258, ROC AUC: 0.7998095238095239\n",
        "Model: Random Forest, Random State: 63, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8258064516129032, ROC AUC: 0.8436190476190476\n",
        "Model: Logistic Regression, Random State: 64, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8258064516129032, ROC AUC: 0.911818181818182\n",
        "Model: Decision Tree, Random State: 64, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8193548387096774, ROC AUC: 0.8208181818181818\n",
        "Model: Random Forest, Random State: 64, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, Accuracy: 0.8193548387096774, ROC AUC: 0.8541818181818182\n",
        "Model: Logistic Regression, Random State: 65, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.832258064516129, ROC AUC: 0.8896190476190475\n",
        "Model: Decision Tree, Random State: 65, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.7935483870967742, ROC AUC: 0.8317142857142857\n",
        "Model: Random Forest, Random State: 65, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, Accuracy: 0.7806451612903226, ROC AUC: 0.8611428571428572\n",
        "Model: Logistic Regression, Random State: 66, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8387096774193549, ROC AUC: 0.8418045705279749\n",
        "Model: Decision Tree, Random State: 66, Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8064516129032258, ROC AUC: 0.7120764381402679\n",
        "Model: Random Forest, Random State: 66, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8129032258064516, ROC AUC: 0.8529353821907013\n",
        "Model: Logistic Regression, Random State: 67, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8129032258064516, ROC AUC: 0.8265815760266372\n",
        "Model: Decision Tree, Random State: 67, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5}, Accuracy: 0.8258064516129032, ROC AUC: 0.7794117647058822\n",
        "Model: Random Forest, Random State: 67, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, Accuracy: 0.8258064516129032, ROC AUC: 0.8288938216796152\n",
        "Model: Logistic Regression, Random State: 68, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8580645161290322, ROC AUC: 0.8815238095238096\n",
        "Model: Decision Tree, Random State: 68, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.8387096774193549, ROC AUC: 0.852\n",
        "Model: Random Forest, Random State: 68, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, Accuracy: 0.8516129032258064, ROC AUC: 0.8634285714285714\n",
        "Model: Logistic Regression, Random State: 69, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8451612903225807, ROC AUC: 0.8738797610156834\n",
        "Model: Decision Tree, Random State: 69, Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10}, Accuracy: 0.8387096774193549, ROC AUC: 0.8378454070201643\n",
        "Model: Random Forest, Random State: 69, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, Accuracy: 0.8451612903225807, ROC AUC: 0.8459671396564601\n",
        "Model: Logistic Regression, Random State: 70, Best Parameters: {'C': 1, 'solver': 'newton-cg'}, Accuracy: 0.8129032258064516, ROC AUC: 0.7992905153099328\n",
        "Model: Decision Tree, Random State: 70, Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}, Accuracy: 0.8, ROC AUC: 0.7588685586258402\n",
        "Model: Random Forest, Random State: 70, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}, Accuracy: 0.7935483870967742, ROC AUC: 0.7967699775952202\n",
        "\n",
        "Best Model Configuration:\n",
        "Model: Random Forest, Random State: 61, Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, Accuracy: 0.8838709677419355, ROC AUC: 0.8890253890253891\n",
        "\n",
        "Best Model Configuration:\n",
        "Model: Logistic Regression, Random State: 37, Best Parameters: {'C': 0.1, 'solver': 'newton-cg'}, Accuracy: 0.8838709677419355, ROC AUC: 0.8819758672699849"
      ],
      "metadata": {
        "id": "MtobN_j3zk5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}